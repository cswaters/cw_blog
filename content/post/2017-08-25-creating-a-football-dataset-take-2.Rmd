---
title: Creating a football dataset, Take Two
author: Cory Waters
date: '2017-08-25'
slug: creating-a-football-dataset-take-two
categories:
  - R
tags:
  - data
---

## A new source

I updated my [previous post](https://www.corywaters.com/08/20/2017/creating-an-nfl-point-spread-dataset/). The data used to create db wasn't reliable and missing games. Because of that I set out to find a new free source. I found a great one. [Dr. Wags Picks - Algorithm Based Sports Handicapper](http://www.drwagpicks.com/p/blog-page.html) makes NCAA and NFL data available on his blog. He even tries to follow the repole format.

This time we're going to grab the NCAA and NFL data. We'll load the `tidyverse` again.

```{r package_imports, warning=FALSE, message=FALSE, error=FALSE}
library(tidyverse)
```

We have two ways of getting the data using R:

1. Get the indivdual links to the files.
2. Get the link format and create a function to change the dates and then iterate over that list.

We're going with option 2. I copied a link from the [Dr Wag's Picks page](http://www.drwagpicks.com/p/blog-page.html).  We will breakdown the structure of that link. But first let's download a season and see how it looks.

```{r wags_odds, message=FALSE}
wags_odds <- 'http://sports.snoozle.net/api?league=cfb&fileType=csvFile&statType=latestodds&startDate=2015-08-01&endDate=2016-02-28&source=drwagpics'

wags <- read_csv(wags_odds)

wags %>% 
  head() %>% 
  knitr::kable()
```

Pretty standard stuff. The first thing to notice is the column names aren't R friendly. We need to deal with that later.

The urls all follow the same strucutre. We're making an api call to `http://sports.snoozle.net/api?` and passing the variables for:

+ league
+ fileType
+ statType
+ startDate
+ endDate
+ source

`league` is going to be either `nfl` or `ncaa`. Here we're using `ncaa`. Leave the file type as csv. There's two `statType` options, `latestodds` or `matchups`. Grab `latestodds` for now. NFL and college football both start their season in year n and end it in year n + 1. Both leagues don't start before August and don't end later than Febrauray. The only piece of the date we need to alter is the year.

The function below takes two arguments, the `.year` and `.sport`. The output is a url that points to a csv file of odds data for the league (called `.sport`) and year. 

```{r format_urls}

format_urls <- function(.year, .sport) {
  base_url <- 'http://sports.snoozle.net/api?league='
  paste0(
    base_url,
    .sport,
    '&fileType=csvFile&statType=latestodds&startDate=',
    .year,
    '-08-01&endDate=',
    .year + 1,
    '-02-28&source=drwagpics'
  )
}
```

Pass a sequence of years to the `format_urls` function via a `map` function from the `purrr` package. The first year in the dataset is 2003 and last season was 2016. The output is a character vector of urls.

```{r create_urls}
odds_urls <- map_chr(2003:2016, 
                     ~format_urls(.year = .x, .sport = 'cfb'))
tail(odds_urls, 3)
```

Next, call `read_csv` on the urls in the `odds_urls` vector. `map_df` passes each url to the `read_csv` function. Then it combines the different files into one dataframe. Another way to do this is `map(odds_urls, read_csv) %>% bind_rows()`. `map_df` acts as a short cut. A nice feature of `map_df` is the ability to add a `.id` column. We're going to use this to assign the season in the dataframe.

```{r download_data, message=FALSE, warning=FALSE}
odds <- map_df(odds_urls, read_csv, .id = 'season')
```

Get the number of unique seasons. 

```{r n_seasons}
n_distinct(odds$season)
```

Instead of renaming the seasons, 1 = 2003, 2 = 2004, etc.,  I prefer to create a *key* tibble and join the two[^fn1]. Create a "throw away" tibble inside the `left_join` function[^fn2]. The `season` column goes to 14 and year maxes out at 2016. Joining the two, every record that has a 1 in the `season` column now has a column `seas` with 2003. Next drop the `season` column and add some R friendly column names  in `set_names`.

Now [export the data](http://r4ds.had.co.nz/data-import.html#writing-to-a-file) to your format of choice.

```{r ncaa_odds, message=FALSE}
odds <- odds %>%
  left_join(tibble(season = as.character(1:14), 
                   seas = 2003:2016)) %>%
  select(-season) %>%
  set_names(c('date', 'away', 'home', 
              'away_sprd', 'home_sprd', 'ou', 
              'seas'))

# export to csv
# write_csv(odds, "cfb_odds.csv")
```


## Adding stat data

#### Improving the url function

Look at the files on the [Dr. Wags Picks cfb data page](http://www.drwagpicks.com/p/blog-page.html). There's two types of data per season. Odds and stats. Alter our url formatting function from above to select which one of these file types to download. It's as easy as changing `&statType=latestodds` to `&statType=matchup` in the url. Add an argument `.stat` to the function.

```{r format_urls_update}
#' update api call to include stat type
format_urls <- function(.year, .sport, .stat) {
  base_url <- 'http://sports.snoozle.net/api?league='
  # stat types = 'latestodds' or 'matchup'
  paste0(
    base_url,
    .sport,
    '&fileType=csvFile&statType=',
    .stat,
    '&startDate=',
    .year,
    '-08-01&endDate=',
    .year + 1,
    '-02-28&source=drwagpics'
  )
}
```

To download the data follow the same procedure we did earlier. 

1. Create the urls to the data
2. Pass those urls to `read_csv` via `map`
3. Add a throw away tibble that maps the year to the index column
4. Drop the index column

```{r matchups, message=FALSE, warning=FALSE}
matchups <- map_chr(2003:2016,
                    ~ format_urls(
                      .year = .x,
                      .sport = 'cfb',
                      .stat = 'matchup'
                    )) %>%
  map_df(read_csv, .id = 'season') %>% 
  left_join(
    tibble(season = as.character(1:14), 
          seas = 2003:2016)
    ) %>% 
  select(-season)
```

If you're following along, you got the warning message that "Duplicated column names were deduplicated." I've surpressed the message here, it's is long and reproduced 14 times. But here's a snippet.

> Duplicated column names deduplicated: 'Rushing Yards' => 'Rushing Yards_1' [20], 'Rushing Attempts' => 'Rushing Attempts_1' [21], 'Passing Yards' => 'Passing Yards_1' [22], 'Passing Attempts' => 'Passing Attempts_1' [23], 'Passing Completions' => 'Passing Completions_1' [24], 'Penalties' => 'Penalties_1' [25], 'Penalty Yards' => 'Penalty Yards_1' [26], 'Fumbles Lost' => 'Fumbles Lost_1' [27], 'Interceptions Thrown' => 'Interceptions Thrown_1' [28], '1st Downs' => '1st Downs_1' [29], '3rd Down Attempts' => '3rd Down Attempts_1' [30], '3rd Down Conversions' => '3rd Down Conversions_1' ...

Take a look at the imported data.

```{r view_matchups}
glimpse(matchups)
```

#### Cleaning up the data

Unlike the odds data the matchup data needs some work before export.

First thing is the `_1` at the end of half the columns. `read_csv` "fixes" duplicate column headers by appending a `_1` to the end of the duplicate name. In this case it isn't helpful. Which team is home? Away? The `_1` doesn't say.

There's some other issues:

1. Column names with spaces
2. Some columns start with a number
3. Column names don't match up with odds data now
4. -999 values instead of `NA`

Base R has a function `make.names`. That function corrects column names into an R acceptable format. For example, it replaces spaces with a period. The `tibble` package has a function `tidy_names`. According to the documentation it "ensures its input has non-missing and unique names..." There's a argument `syntactic =` when set to `TRUE` applies the syntax changes of `make.names`. I'm not a fan of `make.names` and since `read_csv` adds `_1` to the duplicate column names we don't need `make.names`. 

#### Cleaning up header names

I prefer underscores to periods. That's the first thing we'll do. I also make my column headers lowercase when appropriate.

```{r replace_underscores}
matchup_cols <- names(matchups) %>%
  stringr::str_replace_all(' ', '_') %>%
  tolower()
matchup_cols
```

The first set of the duplicated headers is for the away team (called "vis") and the second set the home team. To make the headers more clear delete the `_1` suffix and add the prefix `away_` or `home_`. First replace the `vis_team` and `home_team` columns with `away` and `home`. This makes matching up the matchups dataframe and the odds dataframe easier.

```{r fix_headers}
matchup_cols[2] <- 'away'
matchup_cols[19] <- 'home'
matchup_cols[3:18] <- paste0('away_', matchup_cols[3:18])
matchup_cols[20:35] <- matchup_cols[20:35] %>% 
  stringr::str_replace('_1', '') %>%
  paste0('home_', .)
matchup_cols
```

```{r replace_col_names}
names(matchups) <- matchup_cols
```

Now we're ready to combine the stats and odds.

```{r join_cfb_data}
cfb <- matchups %>% 
  left_join(odds, by = c('date','home','away','seas'))
```

Last thing to do is replace the `-999` values with `NA`.

```{r replace_nas}
cfb <- map_df(cfb, ~na_if(., -999)) 
```

We're ready to export.

```{r eval=FALSE}

write_csv(cfb, 'cfb_db.csv')
```

### Getting the NFL data

Next we're going to download the NFL data. Make sure that the format of the data is the same as the college data. If it is we can apply the same techniques as we did above. This makes the entire process go much faster.

##### Check the format of the odds data

```{r check_nfl_odds, message=FALSE}
nfl_odds <- format_urls(.year = 2016,
            .stat = 'latestodds',
            .sport = 'nfl') %>% 
  read_csv()
```

##### Check the format of the matchup data

```{r check_nfl_matchups, warning=FALSE, message=FALSE}
nfl_matchup <- format_urls(.year = 2016,
                           .stat = 'matchup',
                           .sport = 'nfl') %>% 
  read_csv()
```

Remember, we're going to add a season column to the NFL matchups dataframe. That column is already added to the `matchups` dataframe. If the number of columns match the naming structure is likely the same.

```{r match_col_nums}
ncol(nfl_matchup) + 1 == ncol(matchups)
```

Since everything matches up we can apply the exact same techniques to the NFL data and we did the college.

### Making it reproducible

Create a dataframe with the variables combinations and the url they create. `cross_df` works like `expand.grid`. 

```{r url_df}
seasons <- 2003:2016
stat_types <- c('matchup','latestodds')
sport_type <- 'nfl'

nfl_urls <- cross_df(list(year = seasons,
                          stat = stat_types,
                          sport = sport_type)) %>%
                          mutate(url = format_urls(.year = year, 
                                                   .stat = stat, 
                                                   .sport = sport))
```

##### Get odds data

Filter the `nfl_urls` dataframe to return only records where the `stat` equals "latestodds". Use `pull` to grab the urls as a character vector and pass that to `map_df`. The rest follows the same procedure used earlier for the ncaa data.

```{r nfl_odds, message=FALSE}

odds <- filter(nfl_urls, stat == 'latestodds') %>% 
  pull(url) %>% 
  map_df(read_csv, .id = 'season') %>% 
  left_join(
    tibble(season = as.character(1:14), 
           seas = 2003:2016)
    ) %>% 
  select(-season) %>% 
  set_names(c('date', 'away', 'home', 
              'away_sprd', 'home_sprd', 'ou', 
              'seas'))
```

##### Get matchup data

Filter for every record not equal to "latestodds". This returns the matchup urls. Everything else is the same as above. But use the character vector `matchup_cols` in `set_names`.  We created `matchup_cols` earlier. The vector is the R friendly headers for the matchup data.

```{r nfl_matchup, message=FALSE, warning=FALSE}
matchups <- filter(nfl_urls, stat != 'latestodds') %>% 
  pull(url) %>% 
  map_df(read_csv, .id = 'season') %>% 
  left_join(
    tibble(season = as.character(1:14), 
           seas = 2003:2016)) %>% 
  select(-season) %>% 
  set_names(matchup_cols)
```

Join the odds and matchups data.

```{r nfl_join}
nfl <- matchups %>% 
  left_join(odds, by = c('date','home','away','seas'))
```

Replace `-999` values with `NA`.

```{r nfl_replace_na}
nfl <- map_df(nfl, ~na_if(., -999)) 
```

And export...

```{r nfl_export, eval=FALSE}
write_csv(nfl, 'nfl_db.csv')
```

#### Save for later

Now you have two football datasets. One for the NFL and one for college. Both have 14 seasons worth of data. At the end of this year you can easily append the new data.

```{r echo=FALSE, include=FALSE}
gc()
rm(list = ls())
```


[^fn1]: *Key* tibble is my own term. I could have used `recode`.

[^fn2]: Despite being numeric the `season` column is stored as characters (that's how `map_df` works) That's why we wrap the `1:14` sequence in `as.character`





